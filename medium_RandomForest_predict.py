import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import matplotlib.pyplot as plt
import seaborn as sns
import joblib
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import warnings

warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'Arial Unicode MS']
plt.rcParams['axes.unicode_minus'] = False


class MidTermDataPreprocessor:
    """ä¸­æœŸé¢„æµ‹æ•°æ®é¢„å¤„ç†ç±» - ç”¨äºé¢„æµ‹æ—¶åŠ è½½"""

    def __init__(self):
        self.imputer = None
        self.scaler = None
        self.is_fitted = False
        self.feature_cols = None

    @classmethod
    def load(cls, path):
        """åŠ è½½é¢„å¤„ç†æ¨¡å‹"""
        obj = cls()
        data = joblib.load(path)
        obj.imputer = data['imputer']
        obj.scaler = data['scaler']
        obj.is_fitted = data['is_fitted']
        obj.feature_cols = data['feature_cols']
        return obj

    def transform(self, data):
        """è½¬æ¢æ–°æ•°æ®"""
        if not self.is_fitted:
            raise ValueError("é¢„å¤„ç†æ¨¡å‹å°šæœªæ‹Ÿåˆï¼Œè¯·å…ˆè°ƒç”¨fit_transform")

        data = np.array(data, dtype=float)
        data = np.where(np.isinf(data), np.nan, data)
        data_imputed = self.imputer.transform(data)
        data_scaled = self.scaler.transform(data_imputed)
        return data_scaled


class MidTermPredictor:
    """ä¸­æœŸè´Ÿè·é¢„æµ‹ç±»"""

    def __init__(self):
        self.models = None
        self.preprocessor = None
        self.feature_cols = None
        self.industries = ['å•†ä¸š', 'å¤§å·¥ä¸šç”¨ç”µ', 'æ™®é€šå·¥ä¸š', 'éæ™®å·¥ä¸š']
        self.target_types = ['max', 'min']
        self.fig_dir = "mid_term_prediction_figures"
        import os
        os.makedirs(self.fig_dir, exist_ok=True)

    def load_models(self, model_path='mid_random_forest_models.pkl',
                    preprocessor_path='mid_random_forest_preprocessor.pkl'):
        """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹å’Œé¢„å¤„ç†å·¥å…·"""
        print("æ­£åœ¨åŠ è½½æ¨¡å‹...")
        try:
            # åŠ è½½æ¨¡å‹
            model_dict = joblib.load(model_path)
            self.models = model_dict['models']
            self.feature_cols = model_dict['feature_cols']
            self.industries = model_dict.get('industries', self.industries)
            self.target_types = model_dict.get('target_types', self.target_types)

            # åŠ è½½é¢„å¤„ç†å·¥å…· - ä½¿ç”¨æ­£ç¡®çš„æ–¹å¼
            self.preprocessor = MidTermDataPreprocessor.load(preprocessor_path)

            print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
            print(f"   ç›®æ ‡å˜é‡æ•°é‡: {len(self.models)}")
            print(f"   ç‰¹å¾æ•°é‡: {len(self.feature_cols)}")
            return True

        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False

    def prepare_future_features(self, historical_data, future_dates):
        """ä¸ºæœªæ¥æ—¥æœŸå‡†å¤‡ç‰¹å¾"""
        print("æ­£åœ¨å‡†å¤‡æœªæ¥æ—¥æœŸç‰¹å¾...")

        # å¤åˆ¶å†å²æ•°æ®ç”¨äºç‰¹å¾å·¥ç¨‹
        df_historical = historical_data.copy()
        if 'date' in df_historical.columns:
            df_historical['date'] = pd.to_datetime(df_historical['date'])
            df_historical.set_index('date', inplace=True)

        # åˆ›å»ºæœªæ¥æ—¥æœŸçš„DataFrame
        future_df = pd.DataFrame(index=future_dates)
        future_df['month'] = future_df.index.month
        future_df['day_of_week'] = future_df.index.dayofweek
        future_df['day_of_year'] = future_df.index.dayofyear
        future_df['week_of_year'] = future_df.index.isocalendar().week
        future_df['quarter'] = future_df.index.quarter
        future_df['year'] = future_df.index.year
        future_df['is_weekend'] = (future_df.index.dayofweek >= 5).astype(int)

        # å­£èŠ‚ç‰¹å¾
        future_df['is_spring'] = ((future_df['month'] >= 3) & (future_df['month'] <= 5)).astype(int)
        future_df['is_summer'] = ((future_df['month'] >= 6) & (future_df['month'] <= 8)).astype(int)
        future_df['is_autumn'] = ((future_df['month'] >= 9) & (future_df['month'] <= 11)).astype(int)
        future_df['is_winter'] = ((future_df['month'] <= 2) | (future_df['month'] == 12)).astype(int)

        # èŠ‚å‡æ—¥ç‰¹å¾
        future_df['day_of_month'] = future_df.index.day
        future_df['is_holiday'] = (
                ((future_df['month'] == 1) & (future_df['day_of_month'] <= 3)) |
                ((future_df['month'] == 5) & (future_df['day_of_month'] >= 1) & (future_df['day_of_month'] <= 3)) |
                ((future_df['month'] == 10) & (future_df['day_of_month'] >= 1) & (future_df['day_of_month'] <= 7))
        ).astype(int)

        # å‘¨æœŸæ€§ç‰¹å¾
        future_df['month_sin'] = np.sin(2 * np.pi * future_df['month'] / 12)
        future_df['month_cos'] = np.cos(2 * np.pi * future_df['month'] / 12)
        future_df['day_of_year_sin'] = np.sin(2 * np.pi * future_df['day_of_year'] / 365)
        future_df['day_of_year_cos'] = np.cos(2 * np.pi * future_df['day_of_year'] / 365)
        future_df['day_of_week_sin'] = np.sin(2 * np.pi * future_df['day_of_week'] / 7)
        future_df['day_of_week_cos'] = np.cos(2 * np.pi * future_df['day_of_week'] / 7)

        # ä½¿ç”¨å†å²æ•°æ®è®¡ç®—æ»åç‰¹å¾
        last_date = df_historical.index.max()

        for industry in self.industries:
            for target_type in self.target_types:
                target_col = f'{industry}_{target_type}_power'
                if target_col in df_historical.columns:
                    # æ»åç‰¹å¾ - ä½¿ç”¨å†å²æ•°æ®çš„æœ€åå€¼
                    for lag in [7, 14, 30, 90]:
                        if len(df_historical) > lag:
                            # è·å–æ»åå€¼
                            lag_values = {}
                            for future_date in future_dates:
                                lag_date = future_date - timedelta(days=lag)
                                if lag_date in df_historical.index:
                                    lag_values[future_date] = df_historical.loc[lag_date, target_col]
                                else:
                                    # å¦‚æœæ»åæ—¥æœŸä¸åœ¨å†å²æ•°æ®ä¸­ï¼Œä½¿ç”¨æœ€è¿‘çš„å€¼
                                    available_dates = df_historical[df_historical.index <= future_date].index
                                    if len(available_dates) > 0:
                                        nearest_date = available_dates[-1]
                                        lag_values[future_date] = df_historical.loc[nearest_date, target_col]
                                    else:
                                        lag_values[future_date] = df_historical[target_col].mean()

                            future_df[f'{target_col}_lag_{lag}'] = future_df.index.map(lag_values)

                    # æ»šåŠ¨ç»Ÿè®¡ç‰¹å¾ - ä½¿ç”¨å†å²æ•°æ®çš„æ»šåŠ¨ç»Ÿè®¡
                    for window in [7, 30, 90]:
                        if len(df_historical) >= window:
                            # è®¡ç®—å†å²æ•°æ®çš„æ»šåŠ¨ç»Ÿè®¡
                            rolling_mean = df_historical[target_col].rolling(window=window).mean().iloc[-1]
                            rolling_std = df_historical[target_col].rolling(window=window).std().iloc[-1]
                            rolling_min = df_historical[target_col].rolling(window=window).min().iloc[-1]
                            rolling_max = df_historical[target_col].rolling(window=window).max().iloc[-1]

                            # ä¸ºæ‰€æœ‰æœªæ¥æ—¥æœŸä½¿ç”¨ç›¸åŒçš„æ»šåŠ¨ç»Ÿè®¡å€¼
                            future_df[f'{target_col}_rolling_mean_{window}'] = rolling_mean
                            future_df[f'{target_col}_rolling_std_{window}'] = rolling_std
                            future_df[f'{target_col}_rolling_min_{window}'] = rolling_min
                            future_df[f'{target_col}_rolling_max_{window}'] = rolling_max

        # å¹´åº¦åŒæ¯”ç‰¹å¾ - ä½¿ç”¨å†å²æ•°æ®
        for industry in self.industries:
            for target_type in self.target_types:
                target_col = f'{industry}_{target_type}_power'
                if target_col in df_historical.columns:
                    # è®¡ç®—å»å¹´çš„å¢é•¿ç‡
                    if len(df_historical) > 365:
                        current_year_avg = df_historical[target_col].iloc[-90:].mean()  # æœ€è¿‘3ä¸ªæœˆå¹³å‡
                        last_year_avg = df_historical[target_col].iloc[-455:-365].mean()  # ä¸€å¹´å‰çš„3ä¸ªæœˆå¹³å‡
                        if last_year_avg > 0:
                            growth_rate = (current_year_avg - last_year_avg) / last_year_avg
                        else:
                            growth_rate = 0
                        future_df[f'{target_col}_year_growth'] = growth_rate

        # äº¤äº’ç‰¹å¾
        max_cols = [f'{industry}_max_power' for industry in self.industries
                    if f'{industry}_max_power' in df_historical.columns]
        if len(max_cols) > 1:
            # ä½¿ç”¨å†å²æ•°æ®çš„å¹³å‡å€¼
            total_max = df_historical[max_cols].sum(axis=1).mean()
            avg_max = df_historical[max_cols].mean(axis=1).mean()
            future_df['total_max_power'] = total_max
            future_df['avg_max_power'] = avg_max

        # ç¡®ä¿æ‰€æœ‰ç‰¹å¾åˆ—éƒ½å­˜åœ¨
        for col in self.feature_cols:
            if col not in future_df.columns:
                # å¦‚æœç‰¹å¾ä¸å­˜åœ¨ï¼Œä½¿ç”¨å†å²æ•°æ®çš„å¹³å‡å€¼
                if col in df_historical.columns:
                    future_df[col] = df_historical[col].mean()
                else:
                    future_df[col] = 0

        # åªä¿ç•™éœ€è¦çš„ç‰¹å¾åˆ—
        future_features = future_df[self.feature_cols]

        # å¡«å……ç¼ºå¤±å€¼
        future_features = future_features.fillna(0)

        print(f"âœ… æœªæ¥ç‰¹å¾å‡†å¤‡å®Œæˆï¼Œç‰¹å¾æ•°: {len(future_features.columns)}")
        return future_features

    def predict_future(self, historical_data, days=90):
        """é¢„æµ‹æœªæ¥è´Ÿè·"""
        if not self.models or not self.preprocessor:
            print("âŒ è¯·å…ˆåŠ è½½æ¨¡å‹")
            return None

        print(f"å¼€å§‹é¢„æµ‹æœªæ¥ {days} å¤©è´Ÿè·...")

        # ç”Ÿæˆæœªæ¥æ—¥æœŸ
        last_date = historical_data.index.max() if hasattr(historical_data, 'index') else pd.to_datetime(
            historical_data['date']).max()
        future_dates = pd.date_range(start=last_date + timedelta(days=1), periods=days, freq='D')

        # å‡†å¤‡æœªæ¥ç‰¹å¾
        future_features = self.prepare_future_features(historical_data, future_dates)

        # é¢„å¤„ç†ç‰¹å¾
        try:
            future_processed = self.preprocessor.transform(future_features.values)
        except Exception as e:
            print(f"âŒ ç‰¹å¾é¢„å¤„ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None

        # è¿›è¡Œé¢„æµ‹
        predictions = {}
        for target_name, model in self.models.items():
            try:
                pred = model.predict(future_processed)
                predictions[target_name] = pred
                print(f"âœ… {target_name} é¢„æµ‹å®Œæˆ")
            except Exception as e:
                print(f"âŒ {target_name} é¢„æµ‹å¤±è´¥: {e}")
                predictions[target_name] = np.zeros(len(future_dates))

        # åˆ›å»ºé¢„æµ‹ç»“æœDataFrame
        result_df = pd.DataFrame(index=future_dates)
        for target_name, pred_values in predictions.items():
            result_df[target_name] = pred_values

        print(f"âœ… æœªæ¥ {days} å¤©è´Ÿè·é¢„æµ‹å®Œæˆ")
        return result_df

    def evaluate_prediction(self, actual_data, predicted_data, last_n_days=90):
        """è¯„ä¼°é¢„æµ‹æ•ˆæœï¼ˆå¦‚æœæœ‰å®é™…æ•°æ®ï¼‰"""
        print("\næ­£åœ¨è¯„ä¼°é¢„æµ‹æ•ˆæœ...")

        # è·å–æœ€è¿‘çš„å®é™…æ•°æ®ç”¨äºè¯„ä¼°
        evaluation_period = actual_data.index.max() - timedelta(days=last_n_days)
        actual_recent = actual_data[actual_data.index >= evaluation_period]

        # å¯¹é½å®é™…æ•°æ®å’Œé¢„æµ‹æ•°æ®çš„æ—¶é—´èŒƒå›´
        common_dates = actual_recent.index.intersection(predicted_data.index)

        if len(common_dates) == 0:
            print("âŒ æ²¡æœ‰å…±åŒçš„æ—¶é—´èŒƒå›´ç”¨äºè¯„ä¼°")
            return None

        actual_common = actual_recent.loc[common_dates]
        predicted_common = predicted_data.loc[common_dates]

        evaluation_results = {}

        for target_col in self.models.keys():
            if target_col in actual_common.columns and target_col in predicted_common.columns:
                y_true = actual_common[target_col]
                y_pred = predicted_common[target_col]

                # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
                mae = mean_absolute_error(y_true, y_pred)
                rmse = np.sqrt(mean_squared_error(y_true, y_pred))
                r2 = r2_score(y_true, y_pred)

                # å®‰å…¨çš„MAPEè®¡ç®—
                y_true_safe = np.abs(y_true)
                y_true_safe = np.where(y_true_safe < 1e-10, 1e-10, y_true_safe)
                mape = np.mean(np.abs((y_true - y_pred) / y_true_safe)) * 100

                evaluation_results[target_col] = {
                    'MAE': mae,
                    'RMSE': rmse,
                    'MAPE': mape,
                    'R2': r2
                }

        return evaluation_results

    def plot_predictions(self, historical_data, predicted_data, evaluation_results=None):
        """ç»˜åˆ¶é¢„æµ‹ç»“æœ"""
        print("æ­£åœ¨ç”Ÿæˆé¢„æµ‹å›¾è¡¨...")

        # 1. å„è¡Œä¸šé¢„æµ‹è¶‹åŠ¿å›¾
        fig, axes = plt.subplots(2, 2, figsize=(20, 15))
        axes = axes.flatten()

        for i, industry in enumerate(self.industries):
            if i >= len(axes):
                break

            ax = axes[i]

            # æœ€å¤§è´Ÿè·
            max_col = f'{industry}_max_power'
            if max_col in historical_data.columns and max_col in predicted_data.columns:
                # å†å²æ•°æ®ï¼ˆæœ€è¿‘180å¤©ï¼‰
                hist_start = historical_data.index.max() - timedelta(days=180)
                hist_recent = historical_data[historical_data.index >= hist_start]

                ax.plot(hist_recent.index, hist_recent[max_col],
                        label='å†å²æœ€å¤§è´Ÿè·', color='blue', alpha=0.7, linewidth=1)
                ax.plot(predicted_data.index, predicted_data[max_col],
                        label='é¢„æµ‹æœ€å¤§è´Ÿè·', color='red', alpha=0.8, linewidth=2, linestyle='--')

            # æœ€å°è´Ÿè·
            min_col = f'{industry}_min_power'
            if min_col in historical_data.columns and min_col in predicted_data.columns:
                ax.plot(hist_recent.index, hist_recent[min_col],
                        label='å†å²æœ€å°è´Ÿè·', color='green', alpha=0.7, linewidth=1)
                ax.plot(predicted_data.index, predicted_data[min_col],
                        label='é¢„æµ‹æœ€å°è´Ÿè·', color='orange', alpha=0.8, linewidth=2, linestyle='--')

            ax.set_title(f'{industry}è´Ÿè·é¢„æµ‹', fontweight='bold', fontsize=14)
            ax.set_ylabel('è´Ÿè·å€¼')
            ax.legend()
            ax.grid(True, alpha=0.3)
            ax.tick_params(axis='x', rotation=45)

        plt.tight_layout()
        plt.savefig(f'{self.fig_dir}/industry_predictions.png', dpi=300, bbox_inches='tight')
        plt.close()

        # 2. é¢„æµ‹æ•ˆæœè¯„ä¼°å›¾ï¼ˆå¦‚æœæœ‰è¯„ä¼°ç»“æœï¼‰
        if evaluation_results:
            fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))

            targets = list(evaluation_results.keys())
            short_names = [f"{t.split('_')[0]}-{t.split('_')[1]}" for t in targets]

            # RÂ²æ¯”è¾ƒ
            r2_scores = [results['R2'] for results in evaluation_results.values()]
            bars1 = ax1.bar(range(len(targets)), r2_scores, color='skyblue', alpha=0.7)
            ax1.set_title('å„ç›®æ ‡é¢„æµ‹RÂ²æ¯”è¾ƒ', fontweight='bold')
            ax1.set_ylabel('RÂ² Score')
            ax1.set_xticks(range(len(targets)))
            ax1.set_xticklabels(short_names, rotation=45, ha='right')
            ax1.grid(True, alpha=0.3, axis='y')

            for bar, score in zip(bars1, r2_scores):
                ax1.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.01,
                         f'{score:.3f}', ha='center', va='bottom', fontsize=8)

            # RMSEæ¯”è¾ƒ
            rmse_scores = [results['RMSE'] for results in evaluation_results.values()]
            bars2 = ax2.bar(range(len(targets)), rmse_scores, color='lightcoral', alpha=0.7)
            ax2.set_title('å„ç›®æ ‡é¢„æµ‹RMSEæ¯”è¾ƒ', fontweight='bold')
            ax2.set_ylabel('RMSE')
            ax2.set_xticks(range(len(targets)))
            ax2.set_xticklabels(short_names, rotation=45, ha='right')
            ax2.grid(True, alpha=0.3, axis='y')

            for bar, score in zip(bars2, rmse_scores):
                ax2.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + max(rmse_scores) * 0.01,
                         f'{score:.1f}', ha='center', va='bottom', fontsize=8)

            # MAEæ¯”è¾ƒ
            mae_scores = [results['MAE'] for results in evaluation_results.values()]
            bars3 = ax3.bar(range(len(targets)), mae_scores, color='lightgreen', alpha=0.7)
            ax3.set_title('å„ç›®æ ‡é¢„æµ‹MAEæ¯”è¾ƒ', fontweight='bold')
            ax3.set_ylabel('MAE')
            ax3.set_xticks(range(len(targets)))
            ax3.set_xticklabels(short_names, rotation=45, ha='right')
            ax3.grid(True, alpha=0.3, axis='y')

            for bar, score in zip(bars3, mae_scores):
                ax3.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + max(mae_scores) * 0.01,
                         f'{score:.1f}', ha='center', va='bottom', fontsize=8)

            # MAPEæ¯”è¾ƒ
            mape_scores = [results['MAPE'] for results in evaluation_results.values()]
            bars4 = ax4.bar(range(len(targets)), mape_scores, color='gold', alpha=0.7)
            ax4.set_title('å„ç›®æ ‡é¢„æµ‹MAPEæ¯”è¾ƒ', fontweight='bold')
            ax4.set_ylabel('MAPE (%)')
            ax4.set_xticks(range(len(targets)))
            ax4.set_xticklabels(short_names, rotation=45, ha='right')
            ax4.grid(True, alpha=0.3, axis='y')

            for bar, score in zip(bars4, mape_scores):
                ax4.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + max(mape_scores) * 0.01,
                         f'{score:.1f}%', ha='center', va='bottom', fontsize=8)

            plt.tight_layout()
            plt.savefig(f'{self.fig_dir}/prediction_evaluation.png', dpi=300, bbox_inches='tight')
            plt.close()

        # 3. é¢„æµ‹æ±‡æ€»è¡¨æ ¼
        summary_data = []
        for industry in self.industries:
            for target_type in self.target_types:
                target_col = f'{industry}_{target_type}_power'
                if target_col in predicted_data.columns:
                    pred_values = predicted_data[target_col]
                    summary_data.append({
                        'è¡Œä¸š': industry,
                        'è´Ÿè·ç±»å‹': 'æœ€å¤§å€¼' if target_type == 'max' else 'æœ€å°å€¼',
                        'é¢„æµ‹å¹³å‡å€¼': pred_values.mean(),
                        'é¢„æµ‹æœ€å¤§å€¼': pred_values.max(),
                        'é¢„æµ‹æœ€å°å€¼': pred_values.min(),
                        'é¢„æµ‹æ ‡å‡†å·®': pred_values.std()
                    })

        summary_df = pd.DataFrame(summary_data)
        summary_df.to_csv(f'{self.fig_dir}/prediction_summary.csv', index=False, encoding='utf-8-sig')

        print(f"âœ… é¢„æµ‹å›¾è¡¨å·²ä¿å­˜åˆ°: {self.fig_dir}")
        return summary_df


def main():
    """ä¸»å‡½æ•°ï¼šè¿›è¡Œæœªæ¥3ä¸ªæœˆè´Ÿè·é¢„æµ‹"""
    print("=" * 80)
    print("ä¸­æœŸè´Ÿè·é¢„æµ‹ - æœªæ¥3ä¸ªæœˆé¢„æµ‹")
    print("=" * 80)

    try:
        # åŠ è½½å†å²æ•°æ®
        print("æ­£åœ¨åŠ è½½å†å²æ•°æ®...")
        historical_data = pd.read_csv('industry_weather_data_daily.csv')
        if 'date' in historical_data.columns:
            historical_data['date'] = pd.to_datetime(historical_data['date'])
            historical_data.set_index('date', inplace=True)
        print(f"âœ… å†å²æ•°æ®åŠ è½½æˆåŠŸï¼Œå½¢çŠ¶: {historical_data.shape}")

        # åˆå§‹åŒ–é¢„æµ‹å™¨
        predictor = MidTermPredictor()

        # åŠ è½½æ¨¡å‹
        if not predictor.load_models():
            return None, None

        # è¿›è¡Œæœªæ¥3ä¸ªæœˆé¢„æµ‹
        prediction_days = 90  # 3ä¸ªæœˆ
        predictions = predictor.predict_future(historical_data, days=prediction_days)

        if predictions is None:
            print("âŒ é¢„æµ‹å¤±è´¥")
            return None, None

        # ä¿å­˜é¢„æµ‹ç»“æœ
        predictions.to_csv('future_3month_predictions.csv', encoding='utf-8-sig')
        print("âœ… é¢„æµ‹ç»“æœå·²ä¿å­˜åˆ°: future_3month_predictions.csv")

        # è¯„ä¼°é¢„æµ‹æ•ˆæœï¼ˆå¦‚æœæœ‰æœ€è¿‘çš„å®é™…æ•°æ®ï¼‰
        evaluation_results = None
        # è¿™é‡Œå¯ä»¥å–æ¶ˆæ³¨é‡Šæ¥è¯„ä¼°é¢„æµ‹æ•ˆæœ
        # evaluation_results = predictor.evaluate_prediction(historical_data, predictions)

        # ç”Ÿæˆé¢„æµ‹å›¾è¡¨å’Œæ±‡æ€»
        summary_df = predictor.plot_predictions(historical_data, predictions, evaluation_results)

        # è¾“å‡ºé¢„æµ‹æ€»ç»“
        print("\n" + "=" * 80)
        print("æœªæ¥3ä¸ªæœˆè´Ÿè·é¢„æµ‹æ€»ç»“")
        print("=" * 80)

        print(f"\nğŸ“… é¢„æµ‹æ—¶é—´èŒƒå›´:")
        print(f"   å¼€å§‹æ—¥æœŸ: {predictions.index.min()}")
        print(f"   ç»“æŸæ—¥æœŸ: {predictions.index.max()}")
        print(f"   æ€»é¢„æµ‹å¤©æ•°: {len(predictions)}")

        print(f"\nğŸ“Š å„è¡Œä¸šé¢„æµ‹æ±‡æ€»:")
        for industry in predictor.industries:
            print(f"\n   {industry}:")
            max_col = f'{industry}_max_power'
            min_col = f'{industry}_min_power'

            if max_col in predictions.columns:
                max_vals = predictions[max_col]
                print(f"     æœ€å¤§è´Ÿè· - å¹³å‡: {max_vals.mean():.2f}, èŒƒå›´: {max_vals.min():.2f} ~ {max_vals.max():.2f}")

            if min_col in predictions.columns:
                min_vals = predictions[min_col]
                print(f"     æœ€å°è´Ÿè· - å¹³å‡: {min_vals.mean():.2f}, èŒƒå›´: {min_vals.min():.2f} ~ {min_vals.max():.2f}")

        print(f"\nğŸ“ˆ é¢„æµ‹è¶‹åŠ¿åˆ†æ:")
        # åˆ†æå­£èŠ‚æ€§è¶‹åŠ¿
        predictions['month'] = predictions.index.month
        monthly_trend = predictions.groupby('month').mean()

        for industry in predictor.industries:
            max_col = f'{industry}_max_power'
            if max_col in monthly_trend.columns:
                peak_month = monthly_trend[max_col].idxmax()
                low_month = monthly_trend[max_col].idxmin()
                print(f"   {industry}æœ€å¤§è´Ÿè·: å³°å€¼åœ¨{peak_month}æœˆ, è°·å€¼åœ¨{low_month}æœˆ")

        print(f"\nğŸ’¾ è¾“å‡ºæ–‡ä»¶:")
        print(f"   - é¢„æµ‹æ•°æ®: future_3month_predictions.csv")
        print(f"   - é¢„æµ‹å›¾è¡¨: {predictor.fig_dir}/")
        print(f"   - é¢„æµ‹æ±‡æ€»: {predictor.fig_dir}/prediction_summary.csv")

        return predictions, summary_df

    except Exception as e:
        print(f"âŒ é¢„æµ‹è¿‡ç¨‹å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        return None, None


if __name__ == "__main__":
    predictions, summary = main()