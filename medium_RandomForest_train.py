import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import warnings
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
import joblib
from tqdm import tqdm
import os

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'Arial Unicode MS']
plt.rcParams['axes.unicode_minus'] = False
warnings.filterwarnings('ignore')


class MidTermDataPreprocessor:
    """ä¸­æœŸé¢„æµ‹æ•°æ®é¢„å¤„ç†ç±»"""

    def __init__(self):
        self.imputer = SimpleImputer(strategy='median')
        self.scaler = StandardScaler()
        self.is_fitted = False
        self.feature_cols = None

    def fit_transform(self, data, feature_cols):
        """æ‹Ÿåˆå¹¶è½¬æ¢æ•°æ®"""
        self.feature_cols = feature_cols
        data = np.array(data, dtype=float)

        # å¤„ç†æ— ç©·å€¼
        data = np.where(np.isinf(data), np.nan, data)

        # å¡«å……ç¼ºå¤±å€¼
        data_imputed = self.imputer.fit_transform(data)

        # æ ‡å‡†åŒ–
        data_scaled = self.scaler.fit_transform(data_imputed)

        self.is_fitted = True
        return data_scaled

    def transform(self, data):
        """è½¬æ¢æ–°æ•°æ®"""
        if not self.is_fitted:
            raise ValueError("é¢„å¤„ç†æ¨¡å‹å°šæœªæ‹Ÿåˆï¼Œè¯·å…ˆè°ƒç”¨fit_transform")

        data = np.array(data, dtype=float)
        data = np.where(np.isinf(data), np.nan, data)
        data_imputed = self.imputer.transform(data)
        data_scaled = self.scaler.transform(data_imputed)
        return data_scaled

    def save(self, path):
        """ä¿å­˜é¢„å¤„ç†æ¨¡å‹"""
        joblib.dump({
            'imputer': self.imputer,
            'scaler': self.scaler,
            'is_fitted': self.is_fitted,
            'feature_cols': self.feature_cols
        }, path)

    @classmethod
    def load(cls, path):
        """åŠ è½½é¢„å¤„ç†æ¨¡å‹"""
        obj = cls()
        data = joblib.load(path)
        obj.imputer = data['imputer']
        obj.scaler = data['scaler']
        obj.is_fitted = data['is_fitted']
        obj.feature_cols = data['feature_cols']
        return obj


class MidTermModelTrainer:
    """ä¸­æœŸè´Ÿè·é¢„æµ‹æ¨¡å‹è®­ç»ƒç±»"""

    def __init__(self):
        self.model = None
        self.preprocessor = MidTermDataPreprocessor()
        self.fig_dir = "mid_term_train_figures"
        os.makedirs(self.fig_dir, exist_ok=True)
        self.feature_cols = None
        self.train_history = {
            'iterations': [],
            'train_rmse': [],
            'val_rmse': []
        }
        self.industries = ['å•†ä¸š', 'å¤§å·¥ä¸šç”¨ç”µ', 'æ™®é€šå·¥ä¸š', 'éæ™®å·¥ä¸š']
        self.target_types = ['max', 'min']

    def prepare_midterm_features(self, data):
        """å‡†å¤‡ä¸­æœŸé¢„æµ‹ç‰¹å¾"""
        print("æ­£åœ¨å‡†å¤‡ä¸­æœŸé¢„æµ‹ç‰¹å¾...")

        df = data.copy()

        # ç¡®ä¿æ—¥æœŸæ ¼å¼
        if 'date' in df.columns:
            df['date'] = pd.to_datetime(df['date'])
            df.set_index('date', inplace=True)

        # åŸºç¡€æ—¶é—´ç‰¹å¾
        df['month'] = df.index.month
        df['day_of_week'] = df.index.dayofweek
        df['day_of_year'] = df.index.dayofyear
        df['week_of_year'] = df.index.isocalendar().week
        df['quarter'] = df.index.quarter
        df['year'] = df.index.year
        df['is_weekend'] = (df.index.dayofweek >= 5).astype(int)
        df['is_month_start'] = df.index.is_month_start.astype(int)
        df['is_month_end'] = df.index.is_month_end.astype(int)

        # å­£èŠ‚ç‰¹å¾
        df['is_spring'] = ((df['month'] >= 3) & (df['month'] <= 5)).astype(int)
        df['is_summer'] = ((df['month'] >= 6) & (df['month'] <= 8)).astype(int)
        df['is_autumn'] = ((df['month'] >= 9) & (df['month'] <= 11)).astype(int)
        df['is_winter'] = ((df['month'] <= 2) | (df['month'] == 12)).astype(int)

        # èŠ‚å‡æ—¥ç‰¹å¾ï¼ˆä¸­å›½ä¸»è¦èŠ‚å‡æ—¥ï¼Œæ›´è¯¦ç»†ï¼‰
        df['day_of_month'] = df.index.day
        df['is_holiday'] = (
                ((df['month'] == 1) & (df['day_of_month'] <= 3)) |  # å…ƒæ—¦
                ((df['month'] == 2) & (df['day_of_month'] >= 10) & (df['day_of_month'] <= 17)) |  # æ˜¥èŠ‚
                ((df['month'] == 4) & (df['day_of_month'] >= 3) & (df['day_of_month'] <= 5)) |  # æ¸…æ˜èŠ‚
                ((df['month'] == 5) & (df['day_of_month'] >= 1) & (df['day_of_month'] <= 3)) |  # åŠ³åŠ¨èŠ‚
                ((df['month'] == 6) & (df['day_of_month'] >= 12) & (df['day_of_month'] <= 14)) |  # ç«¯åˆèŠ‚
                ((df['month'] == 9) & (df['day_of_month'] >= 19) & (df['day_of_month'] <= 21)) |  # ä¸­ç§‹èŠ‚
                ((df['month'] == 10) & (df['day_of_month'] >= 1) & (df['day_of_month'] <= 7))  # å›½åº†èŠ‚
        ).astype(int)
        df['is_holiday_prev'] = df['is_holiday'].shift(1).fillna(0).astype(int)
        df['is_holiday_next'] = df['is_holiday'].shift(-1).fillna(0).astype(int)

        # å‘¨æœŸæ€§ç‰¹å¾
        df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)
        df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)
        df['day_of_year_sin'] = np.sin(2 * np.pi * df['day_of_year'] / 365)
        df['day_of_year_cos'] = np.cos(2 * np.pi * df['day_of_year'] / 365)
        df['day_of_week_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7)
        df['day_of_week_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7)

        # ä¸ºæ¯ä¸ªè¡Œä¸šå’Œè´Ÿè·ç±»å‹åˆ›å»ºæ»åç‰¹å¾
        for industry in self.industries:
            for target_type in self.target_types:
                target_col = f'{industry}_{target_type}_power'
                if target_col in df.columns:
                    # æ‰©å±•æ»åç‰¹å¾
                    for lag in [7, 14, 21, 30, 60, 90]:  # å¢åŠ 21å¤©å’Œ60å¤©æ»å
                        if len(df) > lag:
                            df[f'{target_col}_lag_{lag}'] = df[target_col].shift(lag)

                    # æ‰©å±•æ»šåŠ¨ç»Ÿè®¡ç‰¹å¾
                    for window in [7, 14, 30, 60, 90]:  # å¢åŠ 14å¤©å’Œ60å¤©çª—å£
                        df[f'{target_col}_rolling_mean_{window}'] = df[target_col].rolling(
                            window=window, min_periods=1).mean()
                        df[f'{target_col}_rolling_std_{window}'] = df[target_col].rolling(
                            window=window, min_periods=1).std()
                        df[f'{target_col}_rolling_min_{window}'] = df[target_col].rolling(
                            window=window, min_periods=1).min()
                        df[f'{target_col}_rolling_max_{window}'] = df[target_col].rolling(
                            window=window, min_periods=1).max()
                        # å¢åŠ æ»šåŠ¨ä¸­ä½æ•°ç‰¹å¾
                        df[f'{target_col}_rolling_median_{window}'] = df[target_col].rolling(
                            window=window, min_periods=1).median()

        # å¢åŠ æ›´å¤šç»Ÿè®¡ç‰¹å¾
        for industry in self.industries:
            for target_type in self.target_types:
                target_col = f'{industry}_{target_type}_power'
                if target_col in df.columns:
                    # å¹´åº¦åŒæ¯”å’Œç¯æ¯”ç‰¹å¾
                    df[f'{target_col}_year_growth'] = df[target_col].pct_change(periods=365)
                    df[f'{target_col}_month_growth'] = df[target_col].pct_change(periods=30)
                    df[f'{target_col}_week_growth'] = df[target_col].pct_change(periods=7)

        # äº¤å‰ç‰¹å¾ï¼šè¡Œä¸šé—´çš„ç›¸å…³æ€§ç‰¹å¾
        if len(self.industries) > 1:
            for i, industry1 in enumerate(self.industries):
                for industry2 in self.industries[i+1:]:
                    for target_type in self.target_types:
                        col1 = f'{industry1}_{target_type}_power'
                        col2 = f'{industry2}_{target_type}_power'
                        if col1 in df.columns and col2 in df.columns:
                            df[f'{industry1}_{industry2}_{target_type}_ratio'] = df[col1] / (df[col2] + 1e-10)

        # å¡«å……ç¼ºå¤±å€¼ï¼Œä½¿ç”¨æ›´æ™ºèƒ½çš„å¡«å……ç­–ç•¥
        df = df.fillna(method='ffill', limit=7)  # å‘å‰å¡«å……æœ€å¤š7å¤©
        df = df.fillna(method='bfill', limit=7)  # å‘åå¡«å……æœ€å¤š7å¤©
        df = df.fillna(0)  # å‰©ä½™ç¼ºå¤±å€¼å¡«å……0

        # ç¡®ä¿æ‰€æœ‰åˆ—éƒ½æ˜¯æ•°å€¼ç±»å‹
        for col in df.columns:
            df[col] = pd.to_numeric(df[col], errors='coerce')

        df = df.fillna(0)
        print(f"ä¸­æœŸç‰¹å¾å‡†å¤‡å®Œæˆï¼Œæ€»ç‰¹å¾æ•°: {len(df.columns)}")
        return df

    def prepare_targets(self, data):
        """å‡†å¤‡å¤šè¾“å‡ºç›®æ ‡"""
        targets = []
        target_names = []

        for industry in self.industries:
            for target_type in self.target_types:
                target_col = f'{industry}_{target_type}_power'
                if target_col in data.columns:
                    targets.append(data[target_col])
                    target_names.append(target_col)

        if not targets:
            raise ValueError("æ²¡æœ‰æ‰¾åˆ°ä»»ä½•ç›®æ ‡åˆ—ï¼Œè¯·æ£€æŸ¥æ•°æ®")

        y = pd.concat(targets, axis=1)
        y.columns = target_names
        return y, target_names

    def train_midterm_model(self, data):
        """è®­ç»ƒä¸­æœŸè´Ÿè·é¢„æµ‹æ¨¡å‹"""
        print("å¼€å§‹è®­ç»ƒä¸­æœŸè´Ÿè·é¢„æµ‹æ¨¡å‹...")

        # å‡†å¤‡ç‰¹å¾
        df_with_features = self.prepare_midterm_features(data)

        # å‡†å¤‡ç›®æ ‡å˜é‡ï¼ˆå¤šè¾“å‡ºï¼‰
        y, target_names = self.prepare_targets(df_with_features)

        # é€‰æ‹©ç‰¹å¾åˆ—ï¼ˆæ’é™¤ç›®æ ‡åˆ—ï¼‰
        self.feature_cols = [col for col in df_with_features.columns if col not in target_names]
        X = df_with_features[self.feature_cols]

        print(f"ç‰¹å¾æ•°é‡: {len(self.feature_cols)}")
        print(f"ç›®æ ‡æ•°é‡: {len(target_names)}")
        print(f"ç›®æ ‡åˆ—: {target_names}")

        # åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†ï¼ˆæœ€å3ä¸ªæœˆä½œä¸ºéªŒè¯é›†ï¼‰
        split_date = df_with_features.index.max() - timedelta(days=90)
        train_mask = df_with_features.index <= split_date
        val_mask = df_with_features.index > split_date

        X_train, X_val = X[train_mask], X[val_mask]
        y_train, y_val = y[train_mask], y[val_mask]

        print(f"è®­ç»ƒé›†å¤§å°: {len(X_train)}, éªŒè¯é›†å¤§å°: {len(X_val)}")
        print(f"è®­ç»ƒæ—¶é—´èŒƒå›´: {X_train.index.min()} åˆ° {X_train.index.max()}")
        print(f"éªŒè¯æ—¶é—´èŒƒå›´: {X_val.index.min()} åˆ° {X_val.index.max()}")

        # é¢„å¤„ç†æ•°æ®
        X_train_processed = self.preprocessor.fit_transform(X_train.values, self.feature_cols)
        X_val_processed = self.preprocessor.transform(X_val.values)

        # ä¸ºæ¯ä¸ªç›®æ ‡è®­ç»ƒå•ç‹¬çš„æ¨¡å‹ï¼ˆä¸­æœŸé¢„æµ‹é€šå¸¸éœ€è¦æ›´ç²¾ç¡®çš„æ¨¡å‹ï¼‰
        self.models = {}
        all_metrics = {}

        for i, target_name in enumerate(tqdm(target_names, desc="è®­ç»ƒå„è¡Œä¸šæ¨¡å‹")):
            print(f"\nè®­ç»ƒæ¨¡å‹: {target_name}")

            # ä¼˜åŒ–åçš„éšæœºæ£®æ—å‚æ•°
            model = RandomForestRegressor(
                n_estimators=300,  # å¢åŠ æ ‘çš„æ•°é‡
                max_depth=25,       # å¢åŠ æ ‘çš„æ·±åº¦
                min_samples_split=2, # å‡å°‘åˆ†è£‚æ‰€éœ€çš„æœ€å°æ ·æœ¬æ•°
                min_samples_leaf=1,  # å‡å°‘å¶èŠ‚ç‚¹æ‰€éœ€çš„æœ€å°æ ·æœ¬æ•°
                max_features='sqrt',  # ä½¿ç”¨å¹³æ–¹æ ¹ç‰¹å¾æ•°
                random_state=42,
                n_jobs=-1,
                verbose=0
            )

            model.fit(X_train_processed, y_train[target_name])
            self.models[target_name] = model

            # è¯„ä¼°æ¨¡å‹
            y_pred = model.predict(X_val_processed)
            metrics = self.calculate_metrics(y_val[target_name], y_pred)
            all_metrics[target_name] = metrics

            print(f"  {target_name} - RÂ²: {metrics['R2']:.4f}, RMSE: {metrics['RMSE']:.2f}, MAPE: {metrics['MAPE']:.2f}%")

        # è®¡ç®—æ€»ä½“æŒ‡æ ‡
        overall_metrics = self.calculate_overall_metrics(all_metrics)

        print("\nâœ… ä¸­æœŸæ¨¡å‹è®­ç»ƒå®Œæˆ")
        print(f"æ€»ä½“è¯„ä¼°æŒ‡æ ‡:")
        print(f"  - å¹³å‡RÂ²: {overall_metrics['mean_R2']:.4f}")
        print(f"  - å¹³å‡RMSE: {overall_metrics['mean_RMSE']:.2f}")
        print(f"  - å¹³å‡MAE: {overall_metrics['mean_MAE']:.2f}")
        print(f"  - å¹³å‡MAPE: {overall_metrics['mean_MAPE']:.2f}%")

        # ç»˜åˆ¶åˆ†æå›¾è¡¨
        self.plot_midterm_analysis(data, y_val, target_names)
        self.plot_industry_comparison(all_metrics)
        self.plot_feature_importance(X_train, X.columns)

        # ä¿å­˜æ¨¡å‹
        self.save_models()

        return overall_metrics, all_metrics

    def calculate_metrics(self, y_true, y_pred):
        """è®¡ç®—è¯„ä¼°æŒ‡æ ‡"""
        mae = mean_absolute_error(y_true, y_pred)
        mse = mean_squared_error(y_true, y_pred)
        rmse = np.sqrt(mse)

        # é¿å…é™¤é›¶é”™è¯¯
        y_true_safe = np.clip(np.abs(y_true), 1e-10, None)
        mape = np.mean(np.abs((y_true - y_pred) / y_true_safe)) * 100

        r2 = r2_score(y_true, y_pred)

        return {
            'MAE': mae,
            'MSE': mse,
            'RMSE': rmse,
            'MAPE': mape,
            'R2': r2
        }

    def calculate_overall_metrics(self, all_metrics):
        """è®¡ç®—æ€»ä½“æŒ‡æ ‡"""
        mean_r2 = np.mean([metrics['R2'] for metrics in all_metrics.values()])
        mean_rmse = np.mean([metrics['RMSE'] for metrics in all_metrics.values()])
        mean_mae = np.mean([metrics['MAE'] for metrics in all_metrics.values()])
        mean_mape = np.mean([metrics['MAPE'] for metrics in all_metrics.values()])

        return {
            'mean_R2': mean_r2,
            'mean_RMSE': mean_rmse,
            'mean_MAE': mean_mae,
            'mean_MAPE': mean_mape
        }

    def plot_midterm_analysis(self, data, y_val, target_names):
        """ç»˜åˆ¶ä¸­æœŸé¢„æµ‹åˆ†æå›¾è¡¨"""
        print("\næ­£åœ¨ç»˜åˆ¶ä¸­æœŸé¢„æµ‹åˆ†æå›¾è¡¨...")

        # 1. å„è¡Œä¸šè´Ÿè·è¶‹åŠ¿å›¾
        plt.figure(figsize=(15, 12))

        # æœ€å¤§è´Ÿè·è¶‹åŠ¿
        plt.subplot(2, 1, 1)
        for industry in self.industries:
            target_col = f'{industry}_max_power'
            if target_col in data.columns:
                plt.plot(data.index, data[target_col], label=f'{industry}æœ€å¤§è´Ÿè·', alpha=0.7)
        plt.title('å„è¡Œä¸šæœ€å¤§è´Ÿè·è¶‹åŠ¿', fontsize=14, fontweight='bold')
        plt.ylabel('è´Ÿè·å€¼')
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.xticks(rotation=45)

        # æœ€å°è´Ÿè·è¶‹åŠ¿
        plt.subplot(2, 1, 2)
        for industry in self.industries:
            target_col = f'{industry}_min_power'
            if target_col in data.columns:
                plt.plot(data.index, data[target_col], label=f'{industry}æœ€å°è´Ÿè·', alpha=0.7)
        plt.title('å„è¡Œä¸šæœ€å°è´Ÿè·è¶‹åŠ¿', fontsize=14, fontweight='bold')
        plt.ylabel('è´Ÿè·å€¼')
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.xticks(rotation=45)

        plt.tight_layout()
        plt.savefig(f'{self.fig_dir}/industry_load_trends.png', dpi=300, bbox_inches='tight')
        plt.close()

        # 2. å­£èŠ‚æ€§åˆ†æ
        plt.figure(figsize=(15, 10))

        for i, industry in enumerate(self.industries[:4]):  # æœ€å¤šæ˜¾ç¤º4ä¸ªè¡Œä¸š
            plt.subplot(2, 2, i + 1)
            target_col = f'{industry}_max_power'
            if target_col in data.columns:
                monthly_avg = data.groupby(data.index.month)[target_col].mean()
                plt.plot(monthly_avg.index, monthly_avg.values, marker='o', linewidth=2)
                plt.title(f'{industry} - æœˆå¹³å‡è´Ÿè·')
                plt.xlabel('æœˆä»½')
                plt.ylabel('å¹³å‡è´Ÿè·')
                plt.grid(True, alpha=0.3)

        plt.tight_layout()
        plt.savefig(f'{self.fig_dir}/seasonal_analysis.png', dpi=300, bbox_inches='tight')
        plt.close()

        print(f"âœ… å·²ä¿å­˜ä¸­æœŸåˆ†æå›¾è¡¨åˆ°: {self.fig_dir}")

    def plot_industry_comparison(self, all_metrics):
        """ç»˜åˆ¶å„è¡Œä¸šæ€§èƒ½æ¯”è¾ƒå›¾"""
        plt.figure(figsize=(15, 10))

        # RÂ²æ¯”è¾ƒ
        plt.subplot(2, 2, 1)
        r2_scores = [metrics['R2'] for metrics in all_metrics.values()]
        targets = list(all_metrics.keys())
        bars = plt.bar(range(len(targets)), r2_scores, color='skyblue', alpha=0.7)
        plt.title('å„ç›®æ ‡RÂ²æ¯”è¾ƒ', fontsize=12, fontweight='bold')
        plt.ylabel('RÂ² Score')
        plt.xticks(range(len(targets)), targets, rotation=45)

        # åœ¨æŸ±å­ä¸Šæ·»åŠ æ•°å€¼
        for bar, score in zip(bars, r2_scores):
            plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.01,
                     f'{score:.3f}', ha='center', va='bottom', fontsize=8)

        # RMSEæ¯”è¾ƒ
        plt.subplot(2, 2, 2)
        rmse_scores = [metrics['RMSE'] for metrics in all_metrics.values()]
        bars = plt.bar(range(len(targets)), rmse_scores, color='lightcoral', alpha=0.7)
        plt.title('å„ç›®æ ‡RMSEæ¯”è¾ƒ', fontsize=12, fontweight='bold')
        plt.ylabel('RMSE')
        plt.xticks(range(len(targets)), targets, rotation=45)

        for bar, score in zip(bars, rmse_scores):
            plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + max(rmse_scores) * 0.01,
                     f'{score:.1f}', ha='center', va='bottom', fontsize=8)

        # MAEæ¯”è¾ƒ
        plt.subplot(2, 2, 3)
        mae_scores = [metrics['MAE'] for metrics in all_metrics.values()]
        bars = plt.bar(range(len(targets)), mae_scores, color='lightgreen', alpha=0.7)
        plt.title('å„ç›®æ ‡MAEæ¯”è¾ƒ', fontsize=12, fontweight='bold')
        plt.ylabel('MAE')
        plt.xticks(range(len(targets)), targets, rotation=45)

        for bar, score in zip(bars, mae_scores):
            plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + max(mae_scores) * 0.01,
                     f'{score:.1f}', ha='center', va='bottom', fontsize=8)

        # MAPEæ¯”è¾ƒ
        plt.subplot(2, 2, 4)
        mape_scores = [metrics['MAPE'] for metrics in all_metrics.values()]
        bars = plt.bar(range(len(targets)), mape_scores, color='gold', alpha=0.7)
        plt.title('å„ç›®æ ‡MAPEæ¯”è¾ƒ', fontsize=12, fontweight='bold')
        plt.ylabel('MAPE (%)')
        plt.xticks(range(len(targets)), targets, rotation=45)

        for bar, score in zip(bars, mape_scores):
            plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + max(mape_scores) * 0.01,
                     f'{score:.1f}%', ha='center', va='bottom', fontsize=8)

        plt.tight_layout()
        plt.savefig(f'{self.fig_dir}/industry_performance_comparison.png', dpi=300, bbox_inches='tight')
        plt.close()
        print(f"âœ… å·²ä¿å­˜è¡Œä¸šæ€§èƒ½æ¯”è¾ƒå›¾: {self.fig_dir}/industry_performance_comparison.png")

    def plot_feature_importance(self, X_train, feature_names, top_n=20):
        """ç»˜åˆ¶ç‰¹å¾é‡è¦æ€§å›¾"""
        print("ç»˜åˆ¶ç‰¹å¾é‡è¦æ€§å›¾...")
        
        # è®¡ç®—å¹³å‡ç‰¹å¾é‡è¦æ€§ï¼ˆæ‰€æœ‰æ¨¡å‹ï¼‰
        feature_importances = np.zeros(X_train.shape[1])
        for model in self.models.values():
            feature_importances += model.feature_importances_
        feature_importances /= len(self.models)
        
        # è·å–é‡è¦æ€§æ’åº
        indices = np.argsort(feature_importances)[::-1]
        top_indices = indices[:top_n]
        
        # ç»˜åˆ¶å‰Nä¸ªé‡è¦ç‰¹å¾
        plt.figure(figsize=(15, 10))
        plt.title('ç‰¹å¾é‡è¦æ€§ï¼ˆTop {}ï¼‰'.format(top_n), fontsize=14, fontweight='bold')
        plt.bar(range(top_n), feature_importances[top_indices], color='skyblue', alpha=0.8)
        plt.xticks(range(top_n), [feature_names[i] for i in top_indices], rotation=90, fontsize=10)
        plt.ylabel('é‡è¦æ€§åˆ†æ•°')
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        
        # ä¿å­˜å›¾è¡¨
        plt.savefig(f'{self.fig_dir}/feature_importance.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"âœ… å·²ä¿å­˜ç‰¹å¾é‡è¦æ€§å›¾åˆ°: {self.fig_dir}/feature_importance.png")
        
        # æ‰“å°é‡è¦ç‰¹å¾
        print("\nTop 10 é‡è¦ç‰¹å¾:")
        for i in range(10):
            print(f"  {i+1}. {feature_names[indices[i]]}: {feature_importances[indices[i]]:.4f}")
    
    def save_models(self):
        """ä¿å­˜æ¨¡å‹å’Œé¢„å¤„ç†å·¥å…·"""
        # ä¿å­˜æ‰€æœ‰æ¨¡å‹
        model_dict = {
            'models': self.models,
            'feature_cols': self.feature_cols,
            'industries': self.industries,
            'target_types': self.target_types,
            'save_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        }
        joblib.dump(model_dict, 'mid_random_forest_models.pkl')
        self.preprocessor.save('mid_random_forest_preprocessor.pkl')
        print(f"âœ… ä¸­æœŸæ¨¡å‹å·²ä¿å­˜åˆ°: mid_random_forest_models.pkl")
        print(f"âœ… é¢„å¤„ç†å·¥å…·å·²ä¿å­˜åˆ°: mid_random_forest_preprocessor.pkl")


def main():
    """ä¸»å‡½æ•°ï¼šè®­ç»ƒä¸­æœŸè´Ÿè·é¢„æµ‹æ¨¡å‹"""
    print("=" * 80)
    print("ä¸­æœŸè´Ÿè·é¢„æµ‹ - éšæœºæ£®æ—æ¨¡å‹è®­ç»ƒ")
    print("=" * 80)

    try:
        # åŠ è½½æ•°æ®
        print("æ­£åœ¨åŠ è½½æ•°æ®...")
        data = pd.read_csv('industry_weather_data_daily.csv')
        print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸï¼Œå½¢çŠ¶: {data.shape}")

        # æ£€æŸ¥æ•°æ®åˆ—
        print("æ•°æ®åˆ—:", list(data.columns))

        # æ˜¾ç¤ºæ•°æ®åŸºæœ¬ä¿¡æ¯
        if 'date' in data.columns:
            data['date'] = pd.to_datetime(data['date'])
            data.set_index('date', inplace=True)
            print(f"\næ•°æ®åŸºæœ¬ä¿¡æ¯:")
            print(f"æ—¶é—´èŒƒå›´: {data.index.min()} åˆ° {data.index.max()}")
            print(f"æ€»è®°å½•æ•°: {len(data)}")
            print(f"ç‰¹å¾æ•°é‡: {len(data.columns)}")

        # åˆå§‹åŒ–è®­ç»ƒå™¨
        trainer = MidTermModelTrainer()

        # è®­ç»ƒæ¨¡å‹
        overall_metrics, detailed_metrics = trainer.train_midterm_model(data)

        # è¾“å‡ºæ€»ç»“
        print("\n" + "=" * 80)
        print("ä¸­æœŸæ¨¡å‹è®­ç»ƒå®Œæˆæ€»ç»“")
        print("=" * 80)
        print(f"ğŸ“Š æ€»ä½“æ€§èƒ½:")
        print(f"   - å¹³å‡RÂ²: {overall_metrics['mean_R2']:.4f}")
        print(f"   - å¹³å‡RMSE: {overall_metrics['mean_RMSE']:.2f}")
        print(f"   - å¹³å‡MAE: {overall_metrics['mean_MAE']:.2f}")
        print(f"   - å¹³å‡MAPE: {overall_metrics['mean_MAPE']:.2f}%")

        print(f"\nğŸ“ˆ å„è¡Œä¸šè¯¦ç»†æ€§èƒ½:")
        for target, metrics in detailed_metrics.items():
            print(f"   {target}:")
            print(f"     - RÂ²: {metrics['R2']:.4f}")
            print(f"     - RMSE: {metrics['RMSE']:.2f}")
            print(f"     - MAE: {metrics['MAE']:.2f}")
            print(f"     - MAPE: {metrics['MAPE']:.2f}%")

        print(f"\nğŸ“ å¯è§†åŒ–æ–‡ä»¶ä¿å­˜ç›®å½•: {trainer.fig_dir}")

        return overall_metrics, detailed_metrics

    except Exception as e:
        print(f"âŒ è®­ç»ƒè¿‡ç¨‹å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        return None, None


if __name__ == "__main__":
    main()